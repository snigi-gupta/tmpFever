{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiameseNetwork_SentSelection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a50wdi1zaS1W",
        "colab_type": "code",
        "outputId": "bd38afea-a85a-4aa4-d15d-6056aaa872cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!pip install fever-scorer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fever-scorer\n",
            "  Downloading https://files.pythonhosted.org/packages/61/d1/95f1133ded0d74a9d24fe5e15c43f2b3c31f018d0227fa34376f93cf0f08/fever-scorer-2.0.39.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fever-scorer) (1.12.0)\n",
            "Building wheels for collected packages: fever-scorer\n",
            "  Building wheel for fever-scorer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fever-scorer: filename=fever_scorer-2.0.39-cp36-none-any.whl size=3585 sha256=3e11437505765264adfe4340013bb177bacc508dcd558f0e87d6fd824f8f7223\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/f1/2f/bdeac68eff673e4c1cfaab09d14438cd4e4c8a585aeba7ff40\n",
            "Successfully built fever-scorer\n",
            "Installing collected packages: fever-scorer\n",
            "Successfully installed fever-scorer-2.0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG7F0h36t90b",
        "colab_type": "code",
        "outputId": "cf4234fa-4619-4a4b-af69-7b478623f8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UaKI4DduU0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.nn.functional as tnf\n",
        "from fever.scorer import fever_score\n",
        "import pandas as pd\n",
        "import pdb\n",
        "import dill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-H_qmj9uB3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(include_lengths = True, tokenize='spacy')\n",
        "LABEL = data.LabelField()\n",
        "OTHER = data.RawField()\n",
        "OTHER.is_target = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zdaiMPQaNta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset_fields = {\"sent_label\":(\"sent_label\",LABEL), \"sentence\":(\"sentence\",TEXT), \"claim\":(\"claim\",TEXT)}\n",
        "devset_fields = {\"sent_label\":(\"sent_label\",LABEL), \"sentence\":(\"sentence\",TEXT), \"claim\":(\"claim\", TEXT), \n",
        "                 \"org_sentence\":(\"org_sentence\",OTHER), \"docid_claimid_sentno\":(\"docid_claimid_sentno\",OTHER)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzfXBjv_VPO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set paths\n",
        "train_path = \"/content/gdrive/My Drive/NLPWikiData/processed_train_data2.csv\"\n",
        "processed_dev_path = \"/content/gdrive/My Drive/NLPWikiData/processed_golddev_data2.csv\" \n",
        "dev_path = \"/content/gdrive/My Drive/NLPWikiData/dev.jsonl\"\n",
        "# sen_preds_output_path = \"/content/gdrive/My Drive/NLPWikiData/sen_pred_train.jsonl\"\n",
        "vocabulary_path = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o551vDFruKA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = data.TabularDataset(train_path, format=\"CSV\", fields=trainset_fields, skip_header=False)\n",
        "devset = data.TabularDataset(processed_dev_path, format=\"CSV\", fields=devset_fields, skip_header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn5Yvdqou_Mq",
        "colab_type": "code",
        "outputId": "d86e8a45-6209-4fd7-f444-e5a750158f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(len(trainset))\n",
        "print(vars(trainset.examples[0]))\n",
        "print(len(devset))\n",
        "print(vars(devset.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3346905\n",
            "{'sent_label': 'False', 'sentence': ['Nikolaj', 'Coster', '-', 'Waldau', '-LRB-', '-LSB-', 'neɡ̊olaɪ̯', 'kʰʌsd̥ɐ', 'ˈʋald̥ɑʊ̯', '-RSB-', ';', 'born', '27', 'July', '1970', '-RRB-', 'is', 'a', 'Danish', 'actor', ',', 'producer', 'and', 'screenwriter', '.'], 'claim': ['Nikolaj', 'Coster', '-', 'Waldau', 'worked', 'with', 'the', 'Fox', 'Broadcasting', 'Company', '.']}\n",
            "166897\n",
            "{'sent_label': 'True', 'sentence': ['Soul', 'Food', 'is', 'a', '1997', 'American', 'comedy', '-', 'drama', 'film', 'produced', 'by', 'Kenneth', '`', '`', 'Babyface', \"''\", 'Edmonds', ',', 'Tracey', 'Edmonds', 'and', 'Robert', 'Teitel', 'and', 'released', 'by', 'Fox', '2000', 'Pictures', '.'], 'claim': ['Fox', '2000', 'Pictures', 'released', 'the', 'film', 'Soul', 'Food', '.'], 'org_sentence': \"Soul Food is a 1997 American comedy-drama film produced by Kenneth `` Babyface '' Edmonds , Tracey Edmonds and Robert Teitel and released by Fox 2000 Pictures .\", 'docid_claimid_sentno': 'Soul_Food_-LRB-film-RRB-{#--#}137334{#--#}0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnCgAjvrp_QW",
        "colab_type": "code",
        "outputId": "c7c89e5e-6e59-4525-a72d-79b334a7946c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "TEXT.build_vocab(trainset,vectors=\"glove.6B.100d\",unk_init=torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:31, 2.20MB/s]                          \n",
            "100%|█████████▉| 398218/400000 [00:20<00:00, 19792.43it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X_3B_n-yOPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(trainset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g7f3ZvewFfE",
        "colab_type": "code",
        "outputId": "708b6b7e-7fa7-4d1c-f791-155f322836a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# vocabulary of training data (same to be used for dev and test)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 90622\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfqd5zfRzBOP",
        "colab_type": "code",
        "outputId": "2a543512-553a-40fa-83c7-08ff665c8246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(vars(LABEL.vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', 6679593), (',', 5993860), ('the', 5457627), ('in', 3084025), ('and', 3053898), ('of', 2935330), ('a', 2786757), ('is', 2062525), ('was', 1467657), ('to', 1264993), ('The', 1254807), ('-LRB-', 1104248), ('-RRB-', 1104213), ('-', 1028424), ('for', 960542), ('as', 863462), (\"'s\", 799846), ('by', 771416), ('`', 761885), ('an', 748843)]\n",
            "['<unk>', '<pad>', '.', ',', 'the', 'in', 'and', 'of', 'a', 'is']\n",
            "{'freqs': Counter({'False': 3082707, 'True': 264198}), 'itos': ['False', 'True'], 'stoi': defaultdict(<function _default_unk_index at 0x7f8238dc3a60>, {'False': 0, 'True': 1}), 'vectors': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WXY-7JSXdzc",
        "colab_type": "code",
        "outputId": "331afdf6-2e2d-49d4-ab6f-d8160ff147c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "with open(vocabulary_path + \"TEXT_VOCAB_5EPOCH\", mode=\"wb\") as f:\n",
        "    dill.dump(TEXT, f)\n",
        "    print(\"Text Dumping Successfull\")\n",
        "with open(vocabulary_path + \"LABEL_VOCAB_5EPOCH\", mode=\"wb\") as f:\n",
        "    dill.dump(LABEL,f)\n",
        "    print(\"Label Dumping Successfull\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Text Dumping Successfull\n",
            "Label Dumping Successfull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loUGwATBjEdJ",
        "colab_type": "code",
        "outputId": "2fac0031-9f3f-4080-ee8a-dc5994754293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with open(vocabulary_path+\"TEXT_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    X = dill.load(f)\n",
        "    print(\"Loaded Successfully\")\n",
        "with open(vocabulary_path+\"LABEL_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    Y = dill.load(f)\n",
        "    print(\"Loaded Successfully\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Successfully\n",
            "Loaded Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnBaOeDx5Ws",
        "colab_type": "code",
        "outputId": "5a63dc4d-8e7e-4dbb-f3a3-ccbed4f87f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE=128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"We are working with \", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are working with  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCs8MIS6y1tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator = data.BucketIterator(\n",
        "    trainset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: (len(x.claim)),\n",
        "    device = device)\n",
        "dev_iterator = data.BucketIterator(\n",
        "    devset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: (len(x.claim)),\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dQrdKiN0CeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional)\n",
        "        self.fc = nn.Linear(hidden_dim*2*2, output_dim)\n",
        "\n",
        "        # self.dropoutVar = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward_again(self, text, text_lengths):\n",
        "        \n",
        "        # print(text)\n",
        "        # text = [sent_len, batch_size]\n",
        "        # print(\"Text_Shape:  \",text.shape)\n",
        "        # print(\"Text_Length: \",text_lengths)\n",
        "        # print(\"Text_Length_Shape: \",text_lengths.shape)\n",
        "\n",
        "        output = self.embedding(text) #get embeddings\n",
        "        pps = nn.utils.rnn.pack_padded_sequence(output, text_lengths, enforce_sorted=False) #perform packed padded sequence\n",
        "        output2, (hiddenLSTM, cellLSTM) = self.lstm(pps) #lstm\n",
        "        hidden = torch.cat((hiddenLSTM[-2,:,:], hiddenLSTM[-1,:,:]),1) #get concatenated hidden\n",
        "\n",
        "        # print(\"Output:  \",output)\n",
        "        # print(\"Output_Shape:  \",output.shape)\n",
        "        \n",
        "        # print(\"PPS:  \",pps)\n",
        "        # print(\"PPS_Shape:  \",pps.shape)\n",
        "\n",
        "        # print(\"Output2:  \",output2)\n",
        "        # print(\"Output2_Shape:  \",output2.shape)\n",
        "        \n",
        "        # print(\"Hidden:  \",hidden)\n",
        "        # print(\"Hidden_Shape:  \",hidden.shape)\n",
        "        \n",
        "        return hidden\n",
        "\n",
        "    def forward(self, claims, sentences):\n",
        "        claim_text = claims[0]\n",
        "        claim_text_length = claims[1]\n",
        "        sentence_text = sentences[0]\n",
        "        sentence_text_length = sentences[1]\n",
        "\n",
        "        claim_hidden = self.forward_again(claim_text, claim_text_length)\n",
        "        sentence_hidden = self.forward_again(sentence_text, sentence_text_length)\n",
        "\n",
        "        concatenated_hidden = torch.cat((claim_hidden,sentence_hidden), 1)\n",
        "\n",
        "        return self.fc(concatenated_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUVDX3-yG6la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "# DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = LSTM(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCuOcBgeHNAg",
        "colab_type": "code",
        "outputId": "92b5480f-fb00-49b0-b665-729b6b5ab126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,797,434 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAKstWhJJjtI",
        "colab_type": "code",
        "outputId": "880ebbbe-3012-49cd-f230-7f75e3ab4e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([90622, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpFwwivnJke-",
        "colab_type": "code",
        "outputId": "8428c7d8-ed2c-4185-aba0-ce03ada791fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
              "        ...,\n",
              "        [-0.7135,  0.4351, -1.9781,  ..., -0.3908,  2.2369, -0.8613],\n",
              "        [ 0.1130,  0.3988,  0.0366,  ...,  0.5790, -1.6348,  0.1398],\n",
              "        [-0.7313,  1.9365, -0.3453,  ...,  0.1143,  0.0194,  0.5561]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBWQkPBuKBUz",
        "colab_type": "code",
        "outputId": "f4b0cc01-c731-4ee5-9141-4662cbf3e325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
            "        ...,\n",
            "        [-0.7135,  0.4351, -1.9781,  ..., -0.3908,  2.2369, -0.8613],\n",
            "        [ 0.1130,  0.3988,  0.0366,  ...,  0.5790, -1.6348,  0.1398],\n",
            "        [-0.7313,  1.9365, -0.3453,  ...,  0.1143,  0.0194,  0.5561]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb6Ll2XBKD4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfgjFit-KLvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrUzCUqornCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score(probabilities, docid_claimid_sentno, org_sentence, dev_path):\n",
        "    org_dev_data = pd.read_json(dev_path, lines=True)\n",
        "\n",
        "    claim_dict = dict()\n",
        "\n",
        "    for i,val in enumerate(docid_claimid_sentno):\n",
        "        doc_id, claim_id, sentno = docid_claimid_sentno[i].split(\"{#--#}\")\n",
        "        claim_id = int(claim_id)\n",
        "        if claim_id not in claim_dict:\n",
        "            claim_dict[claim_id] = [{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}]\n",
        "        else:\n",
        "            claim_dict[claim_id].extend([{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}])\n",
        "    \n",
        "    file_data = []\n",
        "    fever_data = []\n",
        "    prob_count = 0\n",
        "    # pdb.set_trace()\n",
        "    for org_dev_claim_id, org_dev_claim_label, org_dev_claim, org_dev_evidence_list in zip(org_dev_data['id'], org_dev_data['label'], \n",
        "                                                           org_dev_data['claim'], org_dev_data['evidence']):\n",
        "        temp_data = dict()\n",
        "        fever_dict = dict()\n",
        "\n",
        "        org_dev_claim_id = int(org_dev_claim_id)\n",
        "        predicted_sentences = []\n",
        "        if org_dev_claim_id not in claim_dict:\n",
        "            # that claim id was not in the predictions, hence no predicted sentences\n",
        "            predicted_sentences = []\n",
        "        else:\n",
        "            the_claim_dict = claim_dict[org_dev_claim_id]\n",
        "            for value in the_claim_dict:\n",
        "                #   if value['probability'] >= 0.5:\n",
        "                # print (predicted_sentences)\n",
        "                # print (value)\n",
        "                prob_count +=1\n",
        "                predicted_sentences.append([value['probability'], value['sentno'], value['org_sentence'], value['doc_id']])\n",
        "                            \n",
        "            sorted_predicted_sentences = sorted(predicted_sentences, key=lambda x: x[0], reverse=True)\n",
        "                \n",
        "            # for RTE .jsonl file\n",
        "            temp_data['id'] = org_dev_claim_id\n",
        "            temp_data['claim'] = org_dev_claim\n",
        "            temp_data['sentences'] = [u[2] for u in sorted_predicted_sentences][:5]\n",
        "            temp_data['page_ids'] = [v[3] for v in sorted_predicted_sentences][:5]\n",
        "            temp_data['indices'] = [w[1] for w in sorted_predicted_sentences][:5]\n",
        "            \n",
        "\n",
        "            # for fever score\n",
        "            fever_dict['label'] = org_dev_claim_label\n",
        "            fever_dict['predicted_label'] = org_dev_claim_label\n",
        "            fever_dict['predicted_evidence'] = [[x[3], int(x[1])] for x in sorted_predicted_sentences][:5]\n",
        "            fever_dict['evidence'] = org_dev_evidence_list\n",
        "\n",
        "            file_data.append(temp_data)\n",
        "            fever_data.append(fever_dict)\n",
        "    # pd.DataFrame(file_data).to_json(sen_preds_output_path, orient='records', lines=True)\n",
        "    print('prob_count', prob_count)\n",
        "    return file_data, fever_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv8sAJ0REpNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, file):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "\n",
        "    # doc_ids = []\n",
        "    # sentence_nos = []\n",
        "    # claim_ids = []\n",
        "    docid_claimid_sentno = []\n",
        "    org_sentences = []\n",
        "    predicted_sentences = []\n",
        "    probabilities = []\n",
        "    correct_predictions = 0\n",
        "    total_claims = 0\n",
        "\n",
        "    # epoch_acc = 0\n",
        "\n",
        "  \n",
        "  \n",
        "    with torch.no_grad():\n",
        "  \n",
        "        for i, batch in enumerate(iterator):\n",
        "            model.eval()\n",
        "            \n",
        "            claims, sentences = batch.claim, batch.sentence\n",
        "            \n",
        "            eval_predictions = model(claims, sentences)\n",
        "            probability = tnf.softmax(eval_predictions, 1)\n",
        "            correct_predictions += (torch.max(eval_predictions, 1)[1].view(batch.sent_label.size()) == batch.sent_label).sum().item()\n",
        "            dev_loss = criterion(eval_predictions, batch.sent_label)\n",
        "            \n",
        "            epoch_loss += dev_loss.item()\n",
        "            total_claims += batch.sent_label.size(0)\n",
        "            # epoch_acc += acc.item()\n",
        "\n",
        "            # predicted_sentences.extend(eval_predictions[:,1].tolist())\n",
        "            probabilities.extend(probability[:,1].tolist())\n",
        "            docid_claimid_sentno.extend(batch.docid_claimid_sentno)\n",
        "            org_sentences.extend(batch.org_sentence)\n",
        "\n",
        "        file_data, fever_data = get_score(probabilities, docid_claimid_sentno, org_sentences, dev_path)   \n",
        "        average_accuracy = 100. * correct_predictions / total_claims\n",
        "        print(f'Correct Predictions: {correct_predictions}')\n",
        "        print(f'Total Claims: {total_claims}')\n",
        "        print(f'Validation Loss: {epoch_loss/len(iterator)}')\n",
        "        print(f'Average Accuracy: {average_accuracy}%')\n",
        "        print(f'-----------------------------')\n",
        "\n",
        "    return file_data, fever_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg6L79FTKNhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "\n",
        "\n",
        "def train(model, optimizer, criterion, path, best_f1, epoch_num):\n",
        "  \n",
        "    if not model.training:\n",
        "        model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "  \n",
        "    for i,batch in enumerate(train_iterator):\n",
        "        model.train()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        claims, sentences = batch.claim, batch.sentence\n",
        "        predictions = model(claims, sentences)\n",
        "        \n",
        "        loss = criterion(predictions, batch.sent_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        if (i+1)%5000 == 0:\n",
        "            print(f'BATCH:  {i+1}')\n",
        "\n",
        "    # if (i+1)%10000 == 0:\n",
        "    #   pdb.set_trace()\n",
        "    print(\"--------------------------------\")  \n",
        "    print(f'BATCH: {i+1}')\n",
        "    print(\"loss\", epoch_loss/(i+1))\n",
        "    file_data, fever_data = evaluate(model, dev_iterator, dev_path)\n",
        "    fever_val, accuracy, precision, recall, f1score = fever_score(fever_data)\n",
        "    print(f'Fever Score: {fever_val} | Accuracy: {accuracy}')\n",
        "    print(f'Precision: {precision} | Recall: {recall} | F1Score: {f1score}')\n",
        "\n",
        "    # if f1score > best_f1:\n",
        "    # best_f1 = f1score\n",
        "    print(f'Saving Model. . . ')\n",
        "    torch.save(model.state_dict(), model_path+f'{epoch_num}_{f1score:0.3f}.pt')\n",
        "    print(f'Model Saved Successfully!')\n",
        "    pd.DataFrame(fever_data).to_csv(\"/content/gdrive/My Drive/NLPWikiData/fever_data_output_E\"+f'{epoch_num}.csv')\n",
        "    pd.DataFrame(file_data).to_json(\"/content/gdrive/My Drive/NLPWikiData/sen_pred_train_E\"+f'{epoch_num}.jsonl', orient='records', lines=True)\n",
        "    print(f'jsonl file saved for RTE')\n",
        "    print(\"--------------------------------\")  \n",
        "    print(\"--------------------------------\")  \n",
        "    \n",
        "\n",
        "    return epoch_loss / len(train_iterator), best_f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDendsgd45M8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiHYQgtC5gQw",
        "colab_type": "code",
        "outputId": "1bf03ac7-80b5-44a8-c629-2198b06c402d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "model_path = F\"/content/gdrive/My Drive/sent_selec_E\"\n",
        "best_valid_loss = float('inf')\n",
        "best_f1 = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, best_f1 = train(model, optimizer, criterion, model_path, best_f1, epoch)\n",
        "    # valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # if valid_loss < best_valid_loss:\n",
        "        # best_valid_loss = valid_loss\n",
        "        # torch.save(model.state_dict(), path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    # print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH:  5000\n",
            "BATCH:  10000\n",
            "BATCH:  15000\n",
            "BATCH:  20000\n",
            "BATCH:  25000\n",
            "--------------------------------\n",
            "BATCH: 26148\n",
            "loss 0.20737157987893148\n",
            "prob_count 166897\n",
            "Correct Predictions: 144729\n",
            "Total Claims: 166897\n",
            "Validation Loss: 0.3848355031612278\n",
            "Average Accuracy: 86.71755633714207%\n",
            "-----------------------------\n",
            "Fever Score: 0.7739273927392739 | Accuracy: 1.0\n",
            "Precision: 0.29384188418839774 | Recall: 0.7739273927392739 | F1Score: 0.4259577199333986\n",
            "Saving Model. . . \n",
            "Model Saved Successfully!\n",
            "jsonl file saved for RTE\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Epoch: 01 | Epoch Time: 28m 13s\n",
            "BATCH:  5000\n",
            "BATCH:  10000\n",
            "BATCH:  15000\n",
            "BATCH:  20000\n",
            "BATCH:  25000\n",
            "--------------------------------\n",
            "BATCH: 26148\n",
            "loss 0.19112894987436438\n",
            "prob_count 166897\n",
            "Correct Predictions: 144249\n",
            "Total Claims: 166897\n",
            "Validation Loss: 0.3781695513546101\n",
            "Average Accuracy: 86.42995380384309%\n",
            "-----------------------------\n",
            "Fever Score: 0.7716771677167716 | Accuracy: 1.0\n",
            "Precision: 0.2922667266726449 | Recall: 0.7716771677167716 | F1Score: 0.42396137812516954\n",
            "Saving Model. . . \n",
            "Model Saved Successfully!\n",
            "jsonl file saved for RTE\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Epoch: 02 | Epoch Time: 28m 22s\n",
            "BATCH:  5000\n",
            "BATCH:  10000\n",
            "BATCH:  15000\n",
            "BATCH:  20000\n",
            "BATCH:  25000\n",
            "--------------------------------\n",
            "BATCH: 26148\n",
            "loss 0.18801509459309665\n",
            "prob_count 166897\n",
            "Correct Predictions: 143856\n",
            "Total Claims: 166897\n",
            "Validation Loss: 0.38660250261334556\n",
            "Average Accuracy: 86.19447922970456%\n",
            "-----------------------------\n",
            "Fever Score: 0.7674017401740174 | Accuracy: 1.0\n",
            "Precision: 0.2921617161715959 | Recall: 0.7674017401740174 | F1Score: 0.4232033637241217\n",
            "Saving Model. . . \n",
            "Model Saved Successfully!\n",
            "jsonl file saved for RTE\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Epoch: 03 | Epoch Time: 28m 20s\n",
            "BATCH:  5000\n",
            "BATCH:  10000\n",
            "BATCH:  15000\n",
            "BATCH:  20000\n",
            "BATCH:  25000\n",
            "--------------------------------\n",
            "BATCH: 26148\n",
            "loss 0.18649202422363548\n",
            "prob_count 166897\n",
            "Correct Predictions: 143729\n",
            "Total Claims: 166897\n",
            "Validation Loss: 0.3872868767796667\n",
            "Average Accuracy: 86.11838439276919%\n",
            "-----------------------------\n",
            "Fever Score: 0.7607260726072608 | Accuracy: 1.0\n",
            "Precision: 0.29048154815479454 | Recall: 0.7607260726072608 | F1Score: 0.4204248198514396\n",
            "Saving Model. . . \n",
            "Model Saved Successfully!\n",
            "jsonl file saved for RTE\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Epoch: 04 | Epoch Time: 28m 19s\n",
            "BATCH:  5000\n",
            "BATCH:  10000\n",
            "BATCH:  15000\n",
            "BATCH:  20000\n",
            "BATCH:  25000\n",
            "--------------------------------\n",
            "BATCH: 26148\n",
            "loss 0.18569510388396782\n",
            "prob_count 166897\n",
            "Correct Predictions: 143785\n",
            "Total Claims: 166897\n",
            "Validation Loss: 0.3910891740965697\n",
            "Average Accuracy: 86.15193802165408%\n",
            "-----------------------------\n",
            "Fever Score: 0.770927092709271 | Accuracy: 1.0\n",
            "Precision: 0.2935418541853958 | Recall: 0.770927092709271 | F1Score: 0.4251873554335429\n",
            "Saving Model. . . \n",
            "Model Saved Successfully!\n",
            "jsonl file saved for RTE\n",
            "--------------------------------\n",
            "--------------------------------\n",
            "Epoch: 05 | Epoch Time: 28m 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlMpImmtHqAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAcId0oUHs1J",
        "colab_type": "text"
      },
      "source": [
        "# **Model Testing** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zZ_t-XOHpan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = \"/content/gdrive/My Drive/NLPWikiData/NEWprocessed_test_data.csv\"\n",
        "\n",
        "model_path = \"/content/gdrive/My Drive/sent_selec_0.42889917068716255.pt\"\n",
        "sen_pred_test_path = \"/content/gdrive/My Drive/NLPWikiData/sen_pred_test.jsonl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlNWyD2pIYr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(include_lengths = True, tokenize='spacy')\n",
        "# LABEL = data.LabelField()\n",
        "OTHER = data.RawField()\n",
        "OTHER.is_target = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Md1rhjqIaCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset_fields = {\"sentence\":(\"sentence\",TEXT), \"claim\":(\"claim\", TEXT), \n",
        "                 \"org_sentence\":(\"org_sentence\",OTHER), \"docid_claimid_sentno\":(\"docid_claimid_sentno\",OTHER)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_PwfB8sIid_",
        "colab_type": "code",
        "outputId": "6bc2f99c-acd0-4e68-a0bb-48555aa4069a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/TEXT_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    TEST_TEXT = dill.load(f)\n",
        "    print(\"Text Load Successfull\")\n",
        "with open(\"/content/gdrive/My Drive/LABEL_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    TEST_LABEL = dill.load(f)\n",
        "    print(\"Label Load Successfull\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Load Successfull\n",
            "Label Load Successfull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGQh6dkhJsOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = data.TabularDataset(test_path, format=\"CSV\", fields=testset_fields, skip_header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU2TTrmILBQz",
        "colab_type": "code",
        "outputId": "b676bacb-63bb-469e-c6d9-b59f292bf1f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(testset))\n",
        "print(vars(testset.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "341042\n",
            "{'sentence': ['Henry', 'Spencer', 'is', 'a', 'Canadian', 'computer', 'programmer', 'and', 'space', 'enthusiast', '.'], 'claim': ['Henry', 'Spencer', 'is', 'played', 'by', 'a', 'Greek', 'actor', '.'], 'org_sentence': 'Henry Spencer is a Canadian computer programmer and space enthusiast .', 'docid_claimid_sentno': 'Henry_Spencer_-LRB-disambiguation-RRB-{#--#}89296{#--#}0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PC9LoJVLXhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(testset)\n",
        "# ,vectors=\"glove.6B.100d\",unk_init=torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2zNgTmsLYSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MpVvLvxLmjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.vocab = TEST_TEXT.vocab\n",
        "TEXT.vocab.itos = TEST_TEXT.vocab.itos\n",
        "TEXT.vocab.stoi = TEST_TEXT.vocab.stoi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khfmCWxuLt9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.vocab = TEST_LABEL.vocab\n",
        "LABEL.vocab.itos = TEST_LABEL.vocab.itos\n",
        "LABEL.vocab.stoi = TEST_LABEL.vocab.stoi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYzqoMjLcG4",
        "colab_type": "code",
        "outputId": "37bf23cb-bf41-420a-97d3-8c7958c54d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# vocabulary of training data (same to be used for dev and test)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 90622\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2z0sqzBXrN3",
        "colab_type": "code",
        "outputId": "73a73587-1ab1-43fe-ad42-e46fb2fb193b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(vars(LABEL.vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', 6679593), (',', 5993860), ('the', 5457627), ('in', 3084025), ('and', 3053898), ('of', 2935330), ('a', 2786757), ('is', 2062525), ('was', 1467657), ('to', 1264993), ('The', 1254807), ('-LRB-', 1104248), ('-RRB-', 1104213), ('-', 1028424), ('for', 960542), ('as', 863462), (\"'s\", 799846), ('by', 771416), ('`', 761885), ('an', 748843)]\n",
            "['<unk>', '<pad>', '.', ',', 'the', 'in', 'and', 'of', 'a', 'is']\n",
            "{'freqs': Counter({'False': 3082707, 'True': 264198}), 'itos': ['False', 'True'], 'stoi': defaultdict(<function _default_unk_index at 0x7fde871c97b8>, {'False': 0, 'True': 1}), 'vectors': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlpkDTD-X1Vn",
        "colab_type": "code",
        "outputId": "c15a96aa-8075-44f9-c20d-4048d00f7367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE=128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"We are working with \", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are working with  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xA5pKogX7JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_iterator = data.BucketIterator(\n",
        "    testset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: (len(x.claim)),\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWPzWiYYEpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "# DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = LSTM(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQWO9ZrMYGnS",
        "colab_type": "code",
        "outputId": "7c94a0cb-44ab-4f47-b1b4-1026bcd2fd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model.load_state_dict(torch.load(model_path, map_location=device)) \n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-0f4e80e77699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el70dljasT2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score_test(probabilities, docid_claimid_sentno, org_sentence, test_path):\n",
        "    org_test_data = pd.read_json(dev_path, lines=True)\n",
        "\n",
        "    claim_dict = dict()\n",
        "\n",
        "    for i,val in enumerate(docid_claimid_sentno):\n",
        "        doc_id, claim_id, sentno = docid_claimid_sentno[i].split(\"{#--#}\")\n",
        "        claim_id = int(claim_id)\n",
        "        if claim_id not in claim_dict:\n",
        "            claim_dict[claim_id] = [{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}]\n",
        "        else:\n",
        "            claim_dict[claim_id].extend([{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}])\n",
        "    \n",
        "    file_data = []\n",
        "    fever_data = []\n",
        "    prob_count = 0\n",
        "    # pdb.set_trace()\n",
        "    for org_test_claim_id, org_test_claim, in zip(org_test_data['id'], org_test_data['claim']):\n",
        "        temp_data = dict()\n",
        "        fever_dict = dict()\n",
        "\n",
        "        org_test_claim_id = int(org_test_claim_id)\n",
        "        predicted_sentences = []\n",
        "        if org_test_claim_id not in claim_dict:\n",
        "            # that claim id was not in the predictions, hence no predicted sentences\n",
        "            predicted_sentences = []\n",
        "        else:\n",
        "            the_claim_dict = claim_dict[org_test_claim_id]\n",
        "            for value in the_claim_dict:\n",
        "                #   if value['probability'] >= 0.5:\n",
        "                # print (predicted_sentences)\n",
        "                # print (value)\n",
        "                prob_count +=1\n",
        "                predicted_sentences.append([value['probability'], value['sentno'], value['org_sentence'], value['doc_id']])\n",
        "                            \n",
        "            sorted_predicted_sentences = sorted(predicted_sentences, key=lambda x: x[0], reverse=True)\n",
        "                \n",
        "            # for RTE .jsonl file\n",
        "            temp_data['id'] = org_test_claim_id\n",
        "            temp_data['claim'] = org_test_claim\n",
        "            temp_data['sentences'] = [u[2] for u in sorted_predicted_sentences][:5]\n",
        "            temp_data['page_ids'] = [v[3] for v in sorted_predicted_sentences][:5]\n",
        "            temp_data['indices'] = [w[1] for w in sorted_predicted_sentences][:5]\n",
        "            \n",
        "\n",
        "            # for fever score\n",
        "            # fever_dict['label'] = org_dev_claim_label\n",
        "            # fever_dict['predicted_label'] = org_dev_claim_label\n",
        "            # fever_dict['predicted_evidence'] = [[x[3], int(x[1])] for x in sorted_predicted_sentences][:5]\n",
        "            # fever_dict['evidence'] = org_dev_evidence_list\n",
        "            fever_dict = \"No fever Data\"\n",
        "\n",
        "            file_data.append(temp_data)\n",
        "            # fever_data.append(fever_dict)\n",
        "    pd.DataFrame(file_data).to_json(sen_pred_test_path, orient='records', lines=True)\n",
        "    print('prob_count', prob_count)\n",
        "    return file_data, fever_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBS3U5p2acKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file_data, test_fever_data = evaluate(model, test_iterator, test_path)\n",
        "# test_fever_val, test_accuracy, test_precision, test_recall, f1score = test_fever_score(fever_data)\n",
        "# print(f'Fever Score: {fever_val} | Accuracy: {accuracy}')\n",
        "# print(f'Precision: {precision} | Recall: {recall} | F1Score: {f1score}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0JubGyB1Apo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}