{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Testing_biLSTMSiamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGlhKPlB7GkZ",
        "colab_type": "text"
      },
      "source": [
        "# **Model Testing** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFq7fnz7N8l",
        "colab_type": "code",
        "outputId": "1aa3c481-24dc-4fe2-b4c7-59b603f3dcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip install fever-scorer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fever-scorer\n",
            "  Downloading https://files.pythonhosted.org/packages/61/d1/95f1133ded0d74a9d24fe5e15c43f2b3c31f018d0227fa34376f93cf0f08/fever-scorer-2.0.39.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fever-scorer) (1.12.0)\n",
            "Building wheels for collected packages: fever-scorer\n",
            "  Building wheel for fever-scorer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fever-scorer: filename=fever_scorer-2.0.39-cp36-none-any.whl size=3585 sha256=74e9645e63f24b30c710c6426c026e0baa892a0a3fb1262c92af7707b94e8799\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/f1/2f/bdeac68eff673e4c1cfaab09d14438cd4e4c8a585aeba7ff40\n",
            "Successfully built fever-scorer\n",
            "Installing collected packages: fever-scorer\n",
            "Successfully installed fever-scorer-2.0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5piQ5_Rt7Kp3",
        "colab_type": "code",
        "outputId": "b450a3c6-af85-48d6-a209-306b3c8094b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvB0WY217RcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.nn.functional as tnf\n",
        "from fever.scorer import fever_score\n",
        "import pandas as pd\n",
        "import pdb\n",
        "import dill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf7lzS-Y7i-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEn_BYmP7CRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = \"/content/gdrive/My Drive/NLPWikiData/processed_test_data3.csv\"\n",
        "org_test_path = \"/content/gdrive/My Drive/NLPWikiData/test.jsonl\"\n",
        "model_path = \"/content/gdrive/My Drive/sent_selec_E4_0.425.pt\"\n",
        "sen_pred_test_path = \"/content/gdrive/My Drive/NLPWikiData/sen_pred_test3.jsonl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mXGuail7hRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(include_lengths = True, tokenize='spacy')\n",
        "LABEL = data.LabelField()\n",
        "OTHER = data.RawField()\n",
        "OTHER.is_target = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caiQc2dyDfPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset_fields = {\"sentence\":(\"sentence\",TEXT), \"claim\":(\"claim\", TEXT), \n",
        "                 \"org_sentence\":(\"org_sentence\",OTHER), \"docid_claimid_sentno\":(\"docid_claimid_sentno\",OTHER)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkFvB5gq7zjf",
        "colab_type": "code",
        "outputId": "7a0f55e0-ff13-4c03-b5a8-95e109ce1d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/TEXT_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    TEST_TEXT = dill.load(f)\n",
        "    print(\"Text Load Successfull\")\n",
        "with open(\"/content/gdrive/My Drive/LABEL_VOCAB_5EPOCH\", \"rb\") as f:\n",
        "    TEST_LABEL = dill.load(f)\n",
        "    print(\"Label Load Successfull\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Load Successfull\n",
            "Label Load Successfull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5OvClDB74zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = data.TabularDataset(test_path, format=\"CSV\", fields=testset_fields, skip_header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmtlegK77Mz",
        "colab_type": "code",
        "outputId": "d82bcb8c-b681-410c-91b8-d3a6dbb39a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(testset))\n",
        "print(vars(testset.examples[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "980291\n",
            "{'sentence': ['Henry', 'Spencer', 'is', 'a', 'Canadian', 'computer', 'programmer', 'and', 'space', 'enthusiast', '.'], 'claim': ['Henry', 'Spencer', 'is', 'played', 'by', 'a', 'Greek', 'actor', '.'], 'org_sentence': 'Henry Spencer is a Canadian computer programmer and space enthusiast .', 'docid_claimid_sentno': 'Henry_Spencer_-LRB-disambiguation-RRB-{#--#}89296{#--#}0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHK3k38X79-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V8wQIZs7_LN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDy-BBnF7_IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.vocab = TEST_TEXT.vocab\n",
        "TEXT.vocab.itos = TEST_TEXT.vocab.itos\n",
        "TEXT.vocab.stoi = TEST_TEXT.vocab.stoi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1sW1lMh7_Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.vocab = TEST_LABEL.vocab\n",
        "LABEL.vocab.itos = TEST_LABEL.vocab.itos\n",
        "LABEL.vocab.stoi = TEST_LABEL.vocab.stoi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJuLxdeb7_Bh",
        "colab_type": "code",
        "outputId": "17d5f4eb-5e59-42c3-e6ae-e0a5525f4e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# vocabulary of training data (same to be used for dev and test)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 90622\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfCNx_Qu7-3G",
        "colab_type": "code",
        "outputId": "ff865def-735f-4c0b-f607-9806512be7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(vars(LABEL.vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', 6679593), (',', 5993860), ('the', 5457627), ('in', 3084025), ('and', 3053898), ('of', 2935330), ('a', 2786757), ('is', 2062525), ('was', 1467657), ('to', 1264993), ('The', 1254807), ('-LRB-', 1104248), ('-RRB-', 1104213), ('-', 1028424), ('for', 960542), ('as', 863462), (\"'s\", 799846), ('by', 771416), ('`', 761885), ('an', 748843)]\n",
            "['<unk>', '<pad>', '.', ',', 'the', 'in', 'and', 'of', 'a', 'is']\n",
            "{'freqs': Counter({'False': 3082707, 'True': 264198}), 'itos': ['False', 'True'], 'stoi': defaultdict(<function _default_unk_index at 0x7fbaf8759620>, {'False': 0, 'True': 1}), 'vectors': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72lkv7gg7-qd",
        "colab_type": "code",
        "outputId": "16a5f43c-743c-4d88-a9e4-70bfccf79a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE=128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"We are working with \", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We are working with  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLn6kh2e8ON5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_iterator = data.BucketIterator(\n",
        "    testset, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: (len(x.claim)),\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2lgTj3g8Sss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional)\n",
        "        self.fc = nn.Linear(hidden_dim*2*2, output_dim)\n",
        "\n",
        "        # self.dropoutVar = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward_again(self, text, text_lengths):\n",
        "        \n",
        "        # print(text)\n",
        "        # text = [sent_len, batch_size]\n",
        "        # print(\"Text_Shape:  \",text.shape)\n",
        "        # print(\"Text_Length: \",text_lengths)\n",
        "        # print(\"Text_Length_Shape: \",text_lengths.shape)\n",
        "\n",
        "        output = self.embedding(text) #get embeddings\n",
        "        pps = nn.utils.rnn.pack_padded_sequence(output, text_lengths, enforce_sorted=False) #perform packed padded sequence\n",
        "        output2, (hiddenLSTM, cellLSTM) = self.lstm(pps) #lstm\n",
        "        hidden = torch.cat((hiddenLSTM[-2,:,:], hiddenLSTM[-1,:,:]),1) #get concatenated hidden\n",
        "\n",
        "        # print(\"Output:  \",output)\n",
        "        # print(\"Output_Shape:  \",output.shape)\n",
        "        \n",
        "        # print(\"PPS:  \",pps)\n",
        "        # print(\"PPS_Shape:  \",pps.shape)\n",
        "\n",
        "        # print(\"Output2:  \",output2)\n",
        "        # print(\"Output2_Shape:  \",output2.shape)\n",
        "        \n",
        "        # print(\"Hidden:  \",hidden)\n",
        "        # print(\"Hidden_Shape:  \",hidden.shape)\n",
        "        \n",
        "        return hidden\n",
        "\n",
        "    def forward(self, claims, sentences):\n",
        "        claim_text = claims[0]\n",
        "        claim_text_length = claims[1]\n",
        "        sentence_text = sentences[0]\n",
        "        sentence_text_length = sentences[1]\n",
        "\n",
        "        claim_hidden = self.forward_again(claim_text, claim_text_length)\n",
        "        sentence_hidden = self.forward_again(sentence_text, sentence_text_length)\n",
        "\n",
        "        concatenated_hidden = torch.cat((claim_hidden,sentence_hidden), 1)\n",
        "\n",
        "        return self.fc(concatenated_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15P_0EN38XAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "# DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = LSTM(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrMV54G28aDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model.load_state_dict(torch.load(model_path, map_location=device)) \n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsAKaK9L89Bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, file):\n",
        "  \n",
        "    epoch_loss = 0\n",
        "\n",
        "    # doc_ids = []\n",
        "    # sentence_nos = []\n",
        "    # claim_ids = []\n",
        "    docid_claimid_sentno = []\n",
        "    org_sentences = []\n",
        "    predicted_sentences = []\n",
        "    probabilities = []\n",
        "    correct_predictions = 0\n",
        "    total_claims = 0\n",
        "\n",
        "    # epoch_acc = 0\n",
        "\n",
        "  \n",
        "  \n",
        "    with torch.no_grad():\n",
        "  \n",
        "        for i, batch in enumerate(iterator):\n",
        "            model.eval()\n",
        "            \n",
        "            claims, sentences = batch.claim, batch.sentence\n",
        "            \n",
        "            eval_predictions = model(claims, sentences)\n",
        "            probability = tnf.softmax(eval_predictions, 1)\n",
        "            # correct_predictions += (torch.max(eval_predictions, 1)[1].view(batch.sent_label.size()) == batch.sent_label).sum().item()\n",
        "            # dev_loss = criterion(eval_predictions, batch.sent_label)\n",
        "            \n",
        "            # epoch_loss += dev_loss.item()\n",
        "            # total_claims += batch.sent_label.size(0)\n",
        "            # epoch_acc += acc.item()\n",
        "\n",
        "            # predicted_sentences.extend(eval_predictions[:,1].tolist())\n",
        "            probabilities.extend(probability[:,1].tolist())\n",
        "            docid_claimid_sentno.extend(batch.docid_claimid_sentno)\n",
        "            org_sentences.extend(batch.org_sentence)\n",
        "\n",
        "        file_data, fever_data = get_score_test(probabilities, docid_claimid_sentno, org_sentences, org_test_path)   \n",
        "        # average_accuracy = 100. * correct_predictions / total_claims\n",
        "        # print(f'Correct Predictions: {correct_predictions}')\n",
        "        # print(f'Total Claims: {total_claims}')\n",
        "        # print(f'Validation Loss: {epoch_loss/len(iterator)}')\n",
        "        # print(f'Average Accuracy: {average_accuracy}%')\n",
        "        print(f'-----------------------------')\n",
        "\n",
        "    return file_data, fever_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tDZRjFP8sLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score_test(probabilities, docid_claimid_sentno, org_sentence, org_test_path):\n",
        "    org_test_data = pd.read_json(org_test_path, lines=True)\n",
        "\n",
        "    claim_dict = dict()\n",
        "\n",
        "    for i,val in enumerate(docid_claimid_sentno):\n",
        "        doc_id, claim_id, sentno = docid_claimid_sentno[i].split(\"{#--#}\")\n",
        "        claim_id = int(claim_id)\n",
        "        if claim_id not in claim_dict:\n",
        "            claim_dict[claim_id] = [{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}]\n",
        "        else:\n",
        "            claim_dict[claim_id].extend([{\"probability\": probabilities[i], \"doc_id\": doc_id, \n",
        "                                    \"sentno\": sentno, \"org_sentence\": org_sentence[i]}])\n",
        "    \n",
        "    file_data = []\n",
        "    fever_data = []\n",
        "    prob_count = 0\n",
        "    # pdb.set_trace()\n",
        "    for org_test_claim_id, org_test_claim, in zip(org_test_data['id'], org_test_data['claim']):\n",
        "        temp_data = dict()\n",
        "        fever_dict = dict()\n",
        "\n",
        "        org_test_claim_id = int(org_test_claim_id)\n",
        "        predicted_sentences = []\n",
        "        if org_test_claim_id not in claim_dict:\n",
        "            # that claim id was not in the predictions, hence no predicted sentences\n",
        "            predicted_sentences = []\n",
        "\n",
        "            # for RTE .jsonl file\n",
        "            temp_data['id'] = org_test_claim_id\n",
        "            temp_data['claim'] = org_test_claim\n",
        "            temp_data['sentences'] = []\n",
        "            temp_data['page_ids'] = []\n",
        "            temp_data['indices'] = []\n",
        "            \n",
        "        else:\n",
        "            the_claim_dict = claim_dict[org_test_claim_id]\n",
        "            for value in the_claim_dict:\n",
        "                #   if value['probability'] >= 0.5:\n",
        "                # print (predicted_sentences)\n",
        "                # print (value)\n",
        "                prob_count +=1\n",
        "                predicted_sentences.append([value['probability'], value['sentno'], value['org_sentence'], value['doc_id']])\n",
        "                            \n",
        "            sorted_predicted_sentences = sorted(predicted_sentences, key=lambda x: x[0], reverse=True)\n",
        "                \n",
        "            # for RTE .jsonl file\n",
        "            temp_data['id'] = org_test_claim_id\n",
        "            temp_data['claim'] = org_test_claim\n",
        "            temp_data['sentences'] = [u[2] for u in sorted_predicted_sentences][:5]\n",
        "            temp_data['page_ids'] = [v[3] for v in sorted_predicted_sentences][:5]\n",
        "            temp_data['indices'] = [w[1] for w in sorted_predicted_sentences][:5]\n",
        "            \n",
        "\n",
        "            # for fever score\n",
        "            # fever_dict['label'] = org_dev_claim_label\n",
        "            # fever_dict['predicted_label'] = org_dev_claim_label\n",
        "            # fever_dict['predicted_evidence'] = [[x[3], int(x[1])] for x in sorted_predicted_sentences][:5]\n",
        "            # fever_dict['evidence'] = org_dev_evidence_list\n",
        "            fever_dict = \"No fever Data\"\n",
        "\n",
        "        file_data.append(temp_data)\n",
        "            # fever_data.append(fever_dict)\n",
        "    # pd.DataFrame(file_data).to_json(sen_pred_test_path, orient='records', lines=True)\n",
        "    print('prob_count', prob_count)\n",
        "    return file_data, fever_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFURQcv19Gae",
        "colab_type": "code",
        "outputId": "e6c78e02-1fb5-4cad-e635-d93ce1635894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_file_data, test_fever_data = evaluate(model, test_iterator, test_path)\n",
        "pd.DataFrame(test_file_data).to_json(sen_pred_test_path, orient='records', lines=True)\n",
        "# test_fever_val, test_accuracy, test_precision, test_recall, f1score = test_fever_score(fever_data)\n",
        "# print(f'Fever Score: {fever_val} | Accuracy: {accuracy}')\n",
        "# print(f'Precision: {precision} | Recall: {recall} | F1Score: {f1score}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prob_count 980291\n",
            "-----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99uYOnT2cmlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}